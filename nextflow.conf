cascaded=true
do_coreference=true # whether or not to do coreference in token level
classifier_first=true # if false pipeline starts with extractor if True the first component of the pipeline will be classifier
gpu_classifier=0,1,2,3,4,5,6,7
gpu_number_tsc=2,3
gpu_number_psc=4,5
gpu_number_osc=6,7
gpu_coreference=6
gpu_token=0,1,2,3,4,5
gpu_number_place=7 # This model does not work with multi gpu. Also this is the only model with cpu option in this pipeline (This option is very slow).
input="/data/pipeline_output/multi_task_timesofindia/batch2/" #with backslash at the end
output="/data/pipeline_output/multi_task_timesofindia/batch2/" #with backslash at the end
# input="/PATH_TO_INPUT_FOLDER/" #with backslash at the end
# output="/PATH_TO_OUTPUT_FOLDER/" #with backslash at the end
resume=false
files_start_with="http*" #file name pattern, must end with json if classifier_first is TRUE
source_lang="english"
source=3
doc_batchsize=50
token_batchsize=70 # this doesn't matter anymore
multi_task_max_length=128
multi_task_num_sents=200
# prefix="/home/username/PATH_TO_REPO" # no backslash at the end
prefix="/home/omutlu/emw_pipeline_nf" # no backslash at the end
extractor_script_path=$prefix"/bin/extract/peoples_chaina.py" # path to html to text script
#out_to_csv script's parameters
out_output_type="csv" #type of output
out_name_output_file="outfile" # name of outfile
out_date_key="time" # the key of date in the dataset , =time in thehindu dataset!  ##dont leave space between variable name and equal mark and its value
filter_unprotested_sentence=False
filter_unprotested_documents=False
#TODO : add docs to each parameter
#add python path parameter
sent_batchsize=100
RUN_DOC=false # Whether to run doc level -> Input files must contain "text" and optionally "id"
RUN_SENT=false # Whether to run sent level -> If run_doc is false, then your input files must contain "sentences"
RUN_TOK=true # Whether to run tok level -> If run_doc is false, then your input files must contain ["sentences", "id"]
RUN_POST=false # Whether to run post processing stuff
